## 1.数据集检查

- [ ] 检查输入数据
在网络输入前面进行检查，看数据输入是否正确。例如在做图片处理的时候，是否弄清了图像的高度和宽度，opencv和PIL数据读取的方式是不一样的，opencv是BGR读取，而PIL是RGB读取，色彩通道顺序不一样，还有就是ground_truth的时候一定得注意x，y是否正确对应图像的高和宽。此时可打印或显示若干批量的网络输入和目标输出，确保他们是正确的。

- [ ] 尝试随机数入
尝试传递随机数而不是真是数据，看看错误产生的方式是否想同。如果是，说明在某些时候网络吧数据化为了垃圾，此时可尝试逐层调试，并查看出错的地方。

- [ ] 检查数据加载器
原始数据或许很好，但是数据预处理传输到网络过程中的代码可能有问题，在网络输入前应该打印第一层的输入并仔细检查。

- [ ] 确保输入与输出关联
检查少许输入样本是否有正确的标签，同样也确保shuffle输入样本同样对输出标签有效。

- [ ] 输入与输出之间的关系是否太随机？
如何看待随机呢，好比训练一个网络预测随机抛一枚硬币，预测硬币正反面的情况，输入与输出的关联太少，也就是输入与输出之间的非随机部分可能太小。此时便很难训练出一个有效的模型，这取决于数据性质。

- [ ] 数据集中是否有太多的噪音？
如果你利用python从网上爬取图片时，是否检查过图片与标签的正确性，确保不是因错误标签太多使得模型无法收敛。此时可手动检查输入图片和其标签是否大致正确。

- [x] 打乱（shuffle）数据集
如果训练数据集顺序没有被shuffle，并且每次迭代数据顺序是一致的，这可能会给网络模型训练带来不好的影响。此时可尝试shuffle数据集避免这个问题，shuffle时需要保证输入数据和标签的一致性。

- [ ] 减少类别平衡
在图像分类时，常出现这样的情况，如在数据集中只有一张类别B的图像而有1000张类别A的图像。此时需要从损失函数或其他类别平衡的方法入手解决这个问题。如何凯明提出的FocalLoss，或OHEM正负例平衡方法。

- [ ] 数据集的数据量是否足够？
如果从头训练一个网络（无预训练的模型）时，可能会需要很大的数据。如图像分类，对于每个类别至少需要1000张图像甚至更多，那么此时就需要检查原始数据是否足够。

- [x] 确保使用的批量不是单一标签
如果你的数据集没有shuffle时，可能出现你选中的前1000个图像为同一标签的图像，此时训练便没有意义，可见shuffle的重要性。

- [ ] 缩减批量大小
巨大的batch_size会降低模型的泛化能力

## 数据归一化、数据增强

- [ ] 归一化特征
数据输入时是否归一化到零均值和单位方差了吗？

- [ ] 是否应用过量的数据增强
数据增强有正则化效果，过量的数据增强加上其他形式的正则化（权重L2，中途退出效应）可能导致网络的欠拟合（under-fitting）。

- [ ] 检查与训练模型的预处理过程
如果网络使用了预训练的模型，此时需确保正在使用的归一化和预处理模型的情况相同。如一个图像像素值范围应该在（0,1）（-1,1）或（0,255）的范围，否则可能造成不可估计的后果。

- [ ] 检查训练、验证、测试集的预处理
CS231n指出：任何预处理数据（例如数据均值）必须只在训练数据上进行计算，然后再分发到验证、测试数据中。例如计算均值，然后在整个数据集的每个图像中都减去它，再把数据分发进训练验证、测试集中，这是一个典型错误，其只能在训练数据上进行处理。此外需要在每一个样本或批量（batch）中检查不同的预处理。

## 3.深度网络实现

- [ ] 试着解决某一问题的更简易的版本
这又助于找到问题的根源在哪里。例如，如果目标输出是一个物体类别和坐标，那就试着把预测结果仅限制在物体类别当中（尝试先去掉坐标）。

- [ ] 「碰巧」寻找正确的损失
CS231n的技巧：用小参数进行初始化，不使用正则化。例如，如果我们有10个类别，「碰巧」就意味着我们有10%的概率会得到正确的类别，Softmax损失是正确类别的负log概率：-ln(0.1)=2.302。然后，尝试增加正则化的强度，这样应该会增加损失。

- [x] 检查损失函数
如果损失函数为自己设计的，那么需要仔细检查错误，并且添加单元测试。通常情况下，损失可能会有些不正确并且有损害网络性能的表现。

- [ ] 核实损失输入
如果使用的是框架提供的损失函数，那么需要确保传递给损失函数计算的数据是它所期望的。例如在pytorch中，可能会混淆NLLLoss和CrossEntropyLoss，前者需要softmax输入，而后者则不需要。

- [x] 调整损失权重
如果存在多个损失项，需仔细评估各项的影响力，确保每一项的相应幅值是正确的，防止因为某一项过大而使得网络整体性能较差。这可能会涉及到测试损失权重的不同组合。

- [ ] 监控其他指标
有时损失不是衡量网络是否被正确训练的最佳预测器。如果可以的话，使用其他指标来帮助你，比如精度。

- [ ] 测试任意的自定义层
检查自己定义的任意层并复核以确保他们的运行符合预期。

- [ ] 检查「冷淡」层或变量
检查自己是否无意阻止了一些变量的梯度更新，这些层本来应该是可学的。

- [ ] 扩大网络规模
可能由于网络模型太简单不足以找到合适的参数，此时可适当加入更多的隐藏层。

- [ ] 检查隐维度误差
如果你的输入看上去像（k，W，H）=（64，64，64），那么很容易错过与维度相关的误差。给输入维度输入一些「奇怪」的值（例如每一个维度使用不同的质数），并检查它们是如何通过网络传播的。

- [ ] 探索梯度检查（Gradient checking）
如果你手动实现梯度下降，梯度检查会确保你的反响传播（backpropagation）能像预期中的一样工作。

## 训练问题

- [ ] 一个真正小的数据集
过拟合数据的一个子集，并确保其工作。例如，仅使用1或2个实例训练，并检查你的网络是否学习了区分他们，然后再训练每个分类的更多个实例。

- [x] **检查权重初始化**
如果不确定，请使用Xavier或He初始化。同样，初始化也许会带来最坏的局部最小值，因此尝试不同的初始化，看看是否有效。

- [ ] 改变你的超参数
或许你正在使用一个很糟糕的超参数集。如果可行，尝试一下网格搜索。

- [x] **减少正则化**
太多的正则化可致使网络严重地欠拟合。减少正则化，比如 dropout、批规范、权重／偏差 L2 正则化等。在优秀课程《编程人员的深度学习实战》（http://course.fast.ai）中，Jeremy Howard 建议首先解决欠拟合。这意味着你充分地过拟合数据，并且只有在那时处理过拟合。

- [ ] 给它一些时间
也许你的网络需要更多的时间来训练，在它能做出有意义的预测之前。如果你的损失在稳步下降，那就再多训练一会儿。

- [ ] 从训练模式转换为测试模式
一些框架的层很像批规范、Dropout，而其他的层在训练和测试时表现并不同。转换到适当的模式有助于网络更好地预测。

- [ ] 可视化训练
监督每一层的激活值、权重和更新。确保它们的大小匹配。例如，参数更新的大小（权重和偏差）应该是 1-e3。
考虑可视化库，比如 Tensorboard 和 Crayon。紧要时你也可以打印权重／偏差／激活值。
寻找平均值远大于 0 的层激活。尝试批规范（BatchNormalization）或者RELUs。
Deeplearning 指出了权重和偏差柱状图中的期望值：对于权重，一些时间之后这些柱状图应该有一个近似高斯的（正常）分布。对于偏差，这些柱状图通常会从 0 开始，并经常以近似高斯（这种情况的一个例外是 LSTM）结束。留意那些向 +/- 无限发散的参数。留意那些变得很大的偏差。这有时可能发生在分类的输出层，如果类别的分布不均匀。
检查层更新，它们应该有一个高斯分布。

- [ ] 尝试不同的优化器
优化器的选择不应当妨碍网络的训练，除非你选择了一个特别糟糕的参数。但是，为任务选择一个合适的优化器非常有助于在最短的时间内获得最多的训练。描述你正在使用的算法的论文应当指定优化器；如果没有，我倾向于选择 Adam 或者带有动量的朴素 SGD。

- [ ] 梯度爆炸、梯度消失
检查隐蔽层的最新情况，过大的值可能代表梯度爆炸。这时，梯度截断（Gradient clipping）可能会有所帮助。
检查隐蔽层的激活值。Deeplearning4j 中有一个很好的指导方针：「一个好的激活值标准差大约在 0.5 到 2.0 之间。明显超过这一范围可能就代表着激活值消失或爆炸。」

- [x] **增加、减少学习速率**
低学习速率将会导致你的模型收敛很慢；
高学习速率将会在开始阶段减少你的损失，但是可能会导致你很难找到一个好的解决方案。
试着把你当前的学习速率乘以 0.1 或 10。

- [ ] 克服 NaNs
据我所知，在训练 RNNs 时得到 NaN（Non-a-Number）是一个很大的问题。一些解决它的方法：
减小学习速率，尤其是如果你在前 100 次迭代中就得到了 NaNs。
NaNs 的出现可能是由于用零作了除数，或用零或负数作了自然对数。
Russell Stewart 对如何处理 NaNs 很有心得（http://russellsstewart.com/notes/0.html）。
尝试逐层评估你的网络，这样就会看见 NaNs 到底出现在了哪里。